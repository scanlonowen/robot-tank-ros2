<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>ROS2 Tank — OpenCV.js Demo</title>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css">
<style>
  .hero{padding:2.5rem 0;background:#0f172a;color:#e2e8f0}
  .grid2{display:grid;grid-template-columns:1fr 1fr;gap:12px}
  @media(max-width:900px){.grid2{grid-template-columns:1fr}}
  video,canvas{width:100%;height:auto;border-radius:12px;background:#0b1020}
  .controls{display:flex;gap:.75rem;align-items:center;flex-wrap:wrap;margin:.75rem 0}
  pre{background:#0b1020;color:#c7d2fe;border-radius:12px;padding:12px}
</style>
<!-- OpenCV (WASM) -->
<script async src="https://docs.opencv.org/4.x/opencv.js"
        onload="onOpenCvReady()" onerror="onOpenCvError()"></script>
</head>
<body>
  <nav class="container-fluid">
    <ul><li><strong>ROS2 Tank Robot</strong></li></ul>
    <ul>
      <li><a href="#demo">Demo</a></li>
      <li><a href="https://github.com/scanlonowen/robot-tank-ros2">GitHub</a></li>
    </ul>
  </nav>

  <header class="hero">
    <div class="container">
      <h1>Tracked robot with ROS 2 + OpenCV</h1>
      <p>Webcam red-object tracking in-browser. HSV mask → centroid → velocity hints (vx, wz).</p>
    </div>
  </header>

  <main class="container" id="demo">
    <h2>Live OpenCV.js Demo</h2>
    <div class="grid2">
      <article><h4>Camera</h4><video id="video" playsinline autoplay muted></video></article>
      <article><h4>Processed</h4><canvas id="canvas"></canvas></article>
    </div>

    <div class="controls">
      <button id="startBtn" disabled>Start</button>
      <button id="stopBtn" disabled>Stop</button>
      <label>Resolution
        <select id="resSelect"><option>640x480</option><option>1280x720</option></select>
      </label>
      <label>Hue <input type="number" id="hLow" value="0" min="0" max="179">–<input type="number" id="hHigh" value="10" min="0" max="179"></label>
      <label>S/V min <input type="number" id="sMin" value="120" min="0" max="255"> / <input type="number" id="vMin" value="120" min="0" max="255"></label>
    </div>

    <pre id="stats">Loading OpenCV…</pre>
  </main>

<script>
let video, canvas, ctx, stream, rafId;
let cap, src, hsv, mask1, mask2, mask, kernel, contours, hierarchy;
let running=false;
const $=id=>document.getElementById(id);

function onOpenCvReady(){ $('stats').textContent='OpenCV loaded. Click Start.'; $('startBtn').disabled=false; }
function onOpenCvError(){ $('stats').textContent='Failed to load OpenCV.js'; }

async function start(){
  const [w,h]=$('resSelect').value.split('x').map(Number);
  stream=await navigator.mediaDevices.getUserMedia({video:{width:w,height:h},audio:false});
  video.srcObject=stream; await video.play();
  canvas.width=video.videoWidth; canvas.height=video.videoHeight;

  cap=new cv.VideoCapture(video);
  src=new cv.Mat(video.videoHeight,video.videoWidth,cv.CV_8UC4);
  hsv=new cv.Mat(video.videoHeight,video.videoWidth,cv.CV_8UC3);
  mask1=new cv.Mat(video.videoHeight,video.videoWidth,cv.CV_8UC1);
  mask2=new cv.Mat(video.videoHeight,video.videoWidth,cv.CV_8UC1);
  mask =new cv.Mat(video.videoHeight,video.videoWidth,cv.CV_8UC1);
  kernel=cv.getStructuringElement(cv.MORPH_ELLIPSE,new cv.Size(5,5));
  contours=new cv.MatVector(); hierarchy=new cv.Mat();

  running=true; $('stopBtn').disabled=false; loop();
}
function stop(){
  running=false; if(rafId) cancelAnimationFrame(rafId);
  if(stream) stream.getTracks().forEach(t=>t.stop());
  [cap,src,hsv,mask1,mask2,mask,kernel,contours,hierarchy].forEach(m=>{try{m.delete();}catch{}});
  $('stopBtn').disabled=true; $('stats').textContent+='\\nStopped.';
}
function loop(){
  if(!running) return;
  cap.read(src);
  cv.cvtColor(src,hsv,cv.COLOR_RGBA2RGB);
  cv.cvtColor(hsv,hsv,cv.COLOR_RGB2HSV);

  const hLow=+$('hLow').value, hHigh=+$('hHigh').value, sMin=+$('sMin').value, vMin=+$('vMin').value;
  const low1 =new cv.Mat(hsv.rows,hsv.cols,hsv.type(),[hLow,sMin,vMin,0]);
  const high1=new cv.Mat(hsv.rows,hsv.cols,hsv.type(),[hHigh,255,255,255]);
  const low2 =new cv.Mat(hsv.rows,hsv.cols,hsv.type(),[170,sMin,vMin,0]);
  const high2=new cv.Mat(hsv.rows,hsv.cols,hsv.type(),[179,255,255,255]);
  cv.inRange(hsv,low1,high1,mask1); cv.inRange(hsv,low2,high2,mask2); cv.add(mask1,mask2,mask);
  cv.morphologyEx(mask,mask,cv.MORPH_OPEN,kernel); cv.morphologyEx(mask,mask,cv.MORPH_CLOSE,kernel);

  cv.findContours(mask,contours,hierarchy,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE);
  let cx=null,cy=null,area=0;
  for(let i=0;i<contours.size();i++){ const cnt=contours.get(i); const a=cv.contourArea(cnt);
    if(a>area){ area=a; const m=cv.moments(cnt); if(m.m00){cx=Math.round(m.m10/m.m00); cy=Math.round(m.m01/m.m00);} } }

  ctx.drawImage(video,0,0,canvas.width,canvas.height);
  if(cx!==null){ ctx.beginPath(); ctx.arc(cx,cy,8,0,2*Math.PI); ctx.lineWidth=3; ctx.strokeStyle='#00ff00'; ctx.stroke();
    ctx.beginPath(); ctx.moveTo(cx-15,cy); ctx.lineTo(cx+15,cy); ctx.moveTo(cx,cy-15); ctx.lineTo(cx,cy+15); ctx.stroke(); }

  let vx=0,wz=0;
  if(cx!==null){ const xErr=(cx-canvas.width/2)/(canvas.width/2);
    const targetArea=(canvas.width*canvas.height)*0.05; const aErr=(targetArea-area)/targetArea;
    wz=-0.8*xErr; vx=0.5*Math.max(-1,Math.min(1,aErr)); }
  $('stats').textContent=`area:${Math.round(area)}  centroid:${cx===null?'n/a':cx+','+cy}  vx:${vx.toFixed(2)}  wz:${wz.toFixed(2)}  H:${hLow}-${hHigh}  S>=${sMin} V>=${vMin}`;

  [low1,high1,low2,high2].forEach(m=>m.delete());
  rafId=requestAnimationFrame(loop);
}
window.addEventListener('DOMContentLoaded',()=>{
  video=document.getElementById('video');
  canvas=document.getElementById('canvas'); ctx=canvas.getContext('2d');
  document.getElementById('startBtn').addEventListener('click',start);
  document.getElementById('stopBtn').addEventListener('click',stop);
});
</script>
</body>
</html>
