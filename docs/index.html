<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Robot Tank — Red Object Follower (Web Demo)</title>
<style>
  body { font-family: system-ui, sans-serif; margin: 16px; text-align: center; }
  .wrap { display: inline-block; position: relative; }
  #cam { width: 640px; height: 480px; background:#111; border-radius:12px; object-fit: cover; }
  #overlay { position:absolute; left:0; top:0; width:640px; height:480px; pointer-events:none; }
  .kv { font-family: ui-monospace, monospace; margin: 12px 0; font-size: 1.1em; }
  button { margin: 8px; padding: 8px 14px; font-size: 1rem; }
</style>
</head>
<body>
<h1>Robot Tank — Red Object Follower</h1>
<p>Click <b>Start</b>, allow the camera, then hold a red object. Green dot = centroid; yellow line = center.</p>

<button id="startBtn">Start</button>

<div class="wrap" style="margin-top:12px;">
  <video id="cam" playsinline muted></video>
  <canvas id="overlay"></canvas>
</div>

<div class="kv">vx: <span id="vx">0.00</span>, wz: <span id="wz">0.00</span></div>

<!-- OpenCV.js -->
<script async src="https://docs.opencv.org/4.x/opencv.js"></script>
<script>
/* ----- tiny promise to wait for OpenCV ----- */
const cvReady = new Promise(resolve => {
  // if cv is already injected later, this will be called by the script
  (window.cv ??= {});
  cv.onRuntimeInitialized = resolve;
});

const $ = id => document.getElementById(id);
let loopActive = false;

/* ----- start button handler ----- */
$('startBtn').onclick = async () => {
  try {
    // 1) Ask for FRONT camera (user-facing). User gesture satisfies autoplay rules.
    const cam = $('cam');
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { width: 640, height: 480, facingMode: 'user' }, audio: false
    });
    cam.srcObject = stream;
    await new Promise(res => cam.onloadedmetadata = res);
    await cam.play();

    // 2) Size overlay canvas to match actual video dims
    const w = cam.videoWidth || 640, h = cam.videoHeight || 480;
    const overlay = $('overlay');
    overlay.width = w; overlay.height = h;
    overlay.style.width = cam.clientWidth + 'px';
    overlay.style.height = cam.clientHeight + 'px';
    const ctx = overlay.getContext('2d');

    // 3) Wait for OpenCV to finish loading
    await cvReady;

    // 4) Init OpenCV objects
    const cap  = new cv.VideoCapture(cam);
    const src  = new cv.Mat(h, w, cv.CV_8UC4);
    const bgr  = new cv.Mat(h, w, cv.CV_8UC3);
    const hsv  = new cv.Mat(h, w, cv.CV_8UC3);
    const mask1 = new cv.Mat(), mask2 = new cv.Mat(), mask = new cv.Mat();
    const opened = new cv.Mat(), closed = new cv.Mat();
    const contours = new cv.MatVector(), hierarchy = new cv.Mat();

    // Red thresholds (relaxed for mixed lighting)
    const low1  = new cv.Mat(h, w, hsv.type(), [  0,  80, 40, 0]);
    const high1 = new cv.Mat(h, w, hsv.type(), [ 10, 255,255, 0]);
    const low2  = new cv.Mat(h, w, hsv.type(), [170,  80, 40, 0]);
    const high2 = new cv.Mat(h, w, hsv.type(), [180, 255,255, 0]);
    const kernel = cv.Mat.ones(5,5,cv.CV_8U);

    const P = { target_frac: 0.020, tol_frac: 0.004, turn_gain: 1.2 };
    loopActive = true;

    const onFrame = () => {
      if (!loopActive) return;

      // clear overlay
      ctx.clearRect(0, 0, w, h);

      // read + process
      cap.read(src);
      cv.cvtColor(src, bgr, cv.COLOR_RGBA2BGR);
      cv.cvtColor(bgr, hsv, cv.COLOR_BGR2HSV);
      cv.inRange(hsv, low1, high1, mask1);
      cv.inRange(hsv, low2, high2, mask2);
      cv.bitwise_or(mask1, mask2, mask);
      cv.morphologyEx(mask, opened, cv.MORPH_OPEN, kernel);
      cv.morphologyEx(opened, closed, cv.MORPH_CLOSE, kernel);
      cv.findContours(closed, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      let vx = 0, wz = 0;
      if (contours.size() > 0) {
        // pick largest blob
        let idx = 0, maxA = 0;
        for (let i=0;i<contours.size();i++){
          const a = cv.contourArea(contours.get(i));
          if (a > maxA){ maxA = a; idx = i; }
        }
        const c = contours.get(idx);
        const m = cv.moments(c);
        if (m.m00 > 0) {
          const cx = m.m10 / m.m00, cy = m.m01 / m.m00;
          const cx0 = w / 2;

          // control (matches your ROS node math)
          let err = (cx - cx0) / cx0;
          if (Math.abs(err) < 0.05) err = 0.0;
          wz = Math.max(-1, Math.min(1, -P.turn_gain * err));

          const imgA = w * h, frac = maxA / imgA, ef = P.target_frac - frac;
          vx = Math.abs(ef) < P.tol_frac ? 0.0 : Math.max(-1, Math.min(1, ef / P.target_frac));

          // overlays
          ctx.beginPath(); ctx.moveTo(cx0, 0); ctx.lineTo(cx0, h);
          ctx.lineWidth = 2; ctx.strokeStyle = '#ffff00'; ctx.stroke();
          ctx.beginPath(); ctx.arc(cx, cy, 6, 0, 2*Math.PI); ctx.fillStyle = '#00ff00'; ctx.fill();
        }
      }

      $('vx').textContent = vx.toFixed(2);
      $('wz').textContent = wz.toFixed(2);

      // drive loop from actual video frames if possible
      if ('requestVideoFrameCallback' in cam) cam.requestVideoFrameCallback(onFrame);
      else requestAnimationFrame(onFrame);
    };

    if ('requestVideoFrameCallback' in cam) cam.requestVideoFrameCallback(onFrame);
    else requestAnimationFrame(onFrame);

    // disable start button to avoid duplicate loops
    $('startBtn').disabled = true;

  } catch (err) {
    console.error(err);
    alert('Could not start camera or OpenCV. Check camera permissions and reload.');
  }
};
</script>
</body>
</html>
