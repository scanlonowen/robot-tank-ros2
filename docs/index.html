<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Webcam Color Tracker</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Custom styles for better aesthetics */
        button {
            transition: all 0.2s ease-in-out;
        }
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }
        .data-card {
            background-color: rgba(31, 41, 55, 0.8); /* bg-gray-800 with opacity */
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .canvas-container {
            position: relative;
            width: 100%;
            padding-top: 75%; /* 4:3 Aspect Ratio */
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 0.5rem;
            background-color: #111827; /* bg-gray-900 */
        }
        .status-text {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #9ca3af; /* text-gray-400 */
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200 antialiased">
    <div class="min-h-screen flex flex-col items-center justify-center p-4">
        <main class="w-full max-w-6xl mx-auto">
            <header class="text-center mb-6">
                <h1 class="text-4xl font-bold text-white">Webcam Color Tracker</h1>
                <p class="text-gray-400 mt-2">An in-browser implementation of the ROS image processing node.</p>
            </header>

            <!-- Controls -->
            <div class="flex justify-center items-center space-x-4 mb-6">
                <button id="startButton" class="px-6 py-3 bg-blue-600 text-white font-semibold rounded-lg shadow-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-75">
                    Start Webcam
                </button>
                <button id="stopButton" class="px-6 py-3 bg-red-600 text-white font-semibold rounded-lg shadow-md hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-red-500 focus:ring-opacity-75" disabled>
                    Stop Webcam
                </button>
            </div>

            <!-- Video and Mask Canvases -->
            <div class="grid md:grid-cols-2 gap-6 mb-6">
                <div class="flex flex-col items-center">
                    <h2 class="text-xl font-semibold mb-3 text-white">Live Feed with Overlay</h2>
                    <div id="outputContainer" class="canvas-container shadow-lg">
                         <div id="outputStatus" class="status-text">Webcam is off</div>
                        <canvas id="outputCanvas"></canvas>
                    </div>
                </div>
                <div class="flex flex-col items-center">
                    <h2 class="text-xl font-semibold mb-3 text-white">Processed Color Mask</h2>
                    <div id="maskContainer" class="canvas-container shadow-lg">
                        <div id="maskStatus" class="status-text">Webcam is off</div>
                        <canvas id="maskCanvas"></canvas>
                    </div>
                </div>
            </div>
             <!-- Hidden video element for webcam stream -->
            <video id="webcamVideo" playsinline autoplay muted class="hidden"></video>

            <!-- Data Display -->
            <div class="data-card p-6 rounded-lg shadow-xl">
                <h2 class="text-xl font-semibold mb-4 text-white">Tracking Data (Robot Control Simulation)</h2>
                <div class="grid grid-cols-2 sm:grid-cols-4 gap-4 text-center">
                    <div>
                        <p class="text-sm text-gray-400">Centroid X</p>
                        <p id="centroidX" class="text-2xl font-mono font-bold text-cyan-400">-</p>
                    </div>
                    <div>
                        <p class="text-sm text-gray-400">Area Fraction</p>
                        <p id="areaFrac" class="text-2xl font-mono font-bold text-cyan-400">-</p>
                    </div>
                    <div>
                        <p class="text-sm text-gray-400">Linear Velocity (vx)</p>
                        <p id="vx" class="text-2xl font-mono font-bold text-green-400">-</p>
                    </div>
                    <div>
                        <p class="text-sm text-gray-400">Angular Velocity (wz)</p>
                        <p id="wz" class="text-2xl font-mono font-bold text-green-400">-</p>
                    </div>
                </div>
            </div>
        </main>
    </div>

    <script>
        // --- DOM Elements ---
        const video = document.getElementById('webcamVideo');
        const outputCanvas = document.getElementById('outputCanvas');
        const maskCanvas = document.getElementById('maskCanvas');
        const outputCtx = outputCanvas.getContext('2d', { willReadFrequently: true });
        const maskCtx = maskCanvas.getContext('2d');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const outputStatus = document.getElementById('outputStatus');
        const maskStatus = document.getElementById('maskStatus');

        // --- Data Display Elements ---
        const centroidXEl = document.getElementById('centroidX');
        const areaFracEl = document.getElementById('areaFrac');
        const vxEl = document.getElementById('vx');
        const wzEl = document.getElementById('wz');

        // --- State and Configuration ---
        let stream;
        let animationFrameId;

        // Color detection ranges (copied from the Python script)
        // Note: OpenCV uses H in [0, 179], S in [0, 255], V in [0, 255]
        const low1 = { h: 0, s: 120, v: 70 };
        const high1 = { h: 10, s: 255, v: 255 };
        const low2 = { h: 170, s: 120, v: 70 };
        const high2 = { h: 180, s: 255, v: 255 };

        // Control parameters
        const TARGET_FRAC = 0.020;
        const TOL_FRAC = 0.004;
        const TURN_GAIN = 1.2;

        // --- Core Functions ---

        /**
         * Converts an RGB color value to HSV. Conversion formula
         * adapted from http://en.wikipedia.org/wiki/HSV_color_space.
         * Assumes r, g, and b are contained in the set [0, 255] and
         * returns h in [0, 179], s in [0, 255], and v in [0, 255].
         */
        function rgbToHsv(r, g, b) {
            r /= 255, g /= 255, b /= 255;

            let max = Math.max(r, g, b), min = Math.min(r, g, b);
            let h, s, v = max;
            let d = max - min;
            
            s = max == 0 ? 0 : d / max;

            if (max == min) {
                h = 0; // achromatic
            } else {
                switch (max) {
                    case r: h = (g - b) / d + (g < b ? 6 : 0); break;
                    case g: h = (b - r) / d + 2; break;
                    case b: h = (r - g) / d + 4; break;
                }
                h /= 6;
            }
            
            // Scale to OpenCV's ranges
            return { h: Math.round(h * 179), s: Math.round(s * 255), v: Math.round(v * 255) };
        }

        function processFrame() {
            if (video.readyState < 2) {
                animationFrameId = requestAnimationFrame(processFrame);
                return;
            }

            const width = video.videoWidth;
            const height = video.videoHeight;
            
            // Ensure canvas dimensions match video
            if(outputCanvas.width !== width || outputCanvas.height !== height){
                outputCanvas.width = width;
                outputCanvas.height = height;
                maskCanvas.width = width;
                maskCanvas.height = height;
            }

            // 1. Draw video to output canvas to get pixel data
            outputCtx.drawImage(video, 0, 0, width, height);
            const imageData = outputCtx.getImageData(0, 0, width, height);
            const data = imageData.data;

            const maskData = maskCtx.createImageData(width, height);
            const mask = maskData.data;

            let pixelCount = 0;
            let sumX = 0, sumY = 0;

            // 2. Process each pixel for color
            for (let i = 0; i < data.length; i += 4) {
                const r = data[i];
                const g = data[i + 1];
                const b = data[i + 2];
                const hsv = rgbToHsv(r, g, b);

                let isRed = (hsv.h >= low1.h && hsv.h <= high1.h && hsv.s >= low1.s && hsv.v >= low1.v) ||
                            (hsv.h >= low2.h && hsv.h <= high2.h && hsv.s >= low2.s && hsv.v >= low2.v);

                if (isRed) {
                    mask[i] = 255;
                    mask[i + 1] = 255;
                    mask[i + 2] = 255;
                    const x = (i / 4) % width;
                    const y = Math.floor((i / 4) / width);
                    sumX += x;
                    sumY += y;
                    pixelCount++;
                } else {
                    mask[i] = 0;
                    mask[i + 1] = 0;
                    mask[i + 2] = 0;
                }
                mask[i + 3] = 255; // Alpha
            }

            // 3. Put the generated mask onto the mask canvas
            maskCtx.putImageData(maskData, 0, 0);

            // 4. Calculate centroid and area
            let cx = 0, cy = 0;
            let area = 0;
            if (pixelCount > 0) {
                cx = Math.round(sumX / pixelCount);
                cy = Math.round(sumY / pixelCount);
                area = pixelCount;
            }

            // 5. Draw overlays and calculate control commands
            let vx = 0.0, wz = 0.0;
            const center_x = width / 2;
            const img_area = width * height;
            const area_frac = area / img_area;
            
            // Draw center line
            outputCtx.strokeStyle = 'rgba(255, 255, 0, 0.7)';
            outputCtx.lineWidth = 2;
            outputCtx.beginPath();
            outputCtx.moveTo(center_x, 0);
            outputCtx.lineTo(center_x, height);
            outputCtx.stroke();

            if (area > 50) { // Only process if a significant blob is found
                // --- Control Logic ---
                let err_x = (cx - center_x) / center_x;
                if (Math.abs(err_x) < 0.05) err_x = 0.0;
                wz = -TURN_GAIN * err_x;
                wz = Math.max(-1.0, Math.min(1.0, wz));

                const err_frac = TARGET_FRAC - area_frac;
                if (Math.abs(err_frac) < TOL_FRAC) {
                    vx = 0.0;
                } else {
                    vx = err_frac / TARGET_FRAC;
                    vx = Math.max(-1.0, Math.min(1.0, vx));
                }
                
                // --- Draw Overlays ---
                // Centroid circle
                outputCtx.fillStyle = 'rgba(0, 255, 0, 0.8)';
                outputCtx.beginPath();
                outputCtx.arc(cx, cy, 8, 0, Math.PI * 2);
                outputCtx.fill();
                
                // Centroid coordinates text
                outputCtx.fillStyle = 'white';
                outputCtx.font = '14px Inter';
                outputCtx.fillText(`(${cx}, ${cy})`, cx + 12, cy + 5);
            }
            
            // 6. Update data display
            centroidXEl.textContent = cx || '-';
            areaFracEl.textContent = area_frac.toFixed(4);
            vxEl.textContent = vx.toFixed(2);
            wzEl.textContent = wz.toFixed(2);

            // 7. Loop
            animationFrameId = requestAnimationFrame(processFrame);
        }

        async function startWebcam() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'user',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    },
                    audio: false
                });
                video.srcObject = stream;
                startButton.disabled = true;
                stopButton.disabled = false;
                outputStatus.style.display = 'none';
                maskStatus.style.display = 'none';
                video.onloadedmetadata = () => {
                    cancelAnimationFrame(animationFrameId);
                    processFrame();
                };
            } catch (error) {
                console.error("Error accessing webcam:", error);
                alert("Could not access the webcam. Please ensure you have a webcam and have granted permission.");
            }
        }

        function stopWebcam() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            cancelAnimationFrame(animationFrameId);
            startButton.disabled = false;
            stopButton.disabled = true;

            // Clear canvases and reset status
            outputCtx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
            maskCtx.clearRect(0, 0, maskCanvas.width, maskCanvas.height);
            outputStatus.style.display = 'block';
            maskStatus.style.display = 'block';

            // Reset data
            centroidXEl.textContent = '-';
            areaFracEl.textContent = '-';
            vxEl.textContent = '-';
            wzEl.textContent = '-';
        }

        // --- Event Listeners ---
        startButton.addEventListener('click', startWebcam);
        stopButton.addEventListener('click', stopWebcam);
    </script>
</body>
</html>

